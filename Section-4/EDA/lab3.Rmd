---
title: 'Lab 3: Exploratory Data Analysis'
subtitle: "BMI 206"
author: "_Abe Arab_"
date: "_11/07/2024_"
output: html_document
---

**Prepare the data.**

The data used in this exercise was generated by performing whole genome sequencing analysis of metastatic prostate tumors. This assay allows us to identify structural variations in tumor genomes such as duplications, inversions, and large deletions.

For more details on the analysis and results, see [Quigley et al. Cell 2018](https://pubmed.ncbi.nlm.nih.gov/30033370).

We counted the number of structural variations in each tumor sample. For our purposes, variants come in five types: inversions, deletions, duplications, insertions, and translocations. We also assessed each biopsy to identify biallelic inactivating mutations in each gene. Read in summaries of the number of structural variants present in each tumor and the presence/absence of mutations for a few selected genes.

```{r}

# Change working_folder to the path where the files are located
working_folder = '.'
fn_sum = paste0( working_folder, '/SV_summary_table.txt' )
fn_mut = paste0( working_folder, '/WCDT_mutations.txt')
sv = read.table(fn_sum, sep='\t', header=TRUE, stringsAsFactors=FALSE)

mut = read.table(fn_mut, sep='\t', header=TRUE, stringsAsFactors=FALSE)

# if you don't have ggplot2 or reshape2 installed, un-comment and run the next two lines:
#install.packages("ggplot2")
#install.packages("reshape2")
library(tidyverse)
library(ggplot2)
library(reshape2)
```

### Question 1: The variant showcase showdown

The *sv* matrix object reports counts of five types of structural variants (SV) in 101 patient tumor biopsies.

**QUESTION 1.1**: Plot a summary of the distributions for each type of SV individually. Do any of the distributions have outliers, defined as "values that exceed the whiskers of a boxplot"?

*Yes, there are some outliers in the distributions of the SV types.*

```{r eval=TRUE}
# ANSWER 1.1
sv %>% 
  rownames_to_column('patients') %>%
  melt(id.vars = 'patients', variable.name = 'SV_type', value.name = 'count') %>%
  # pivot_longer(-patients, names_to = 'SV_type', values_to = 'count') %>%
  ggplot(aes(x = SV_type, y = count)) +
  geom_boxplot() +
  geom_violin(fill = 'blue', alpha = 0.5) +
  # geom_jitter(width = 0.2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  

```

**QUESTION 1.2** Which SV types are most frequent? Least frequent?

*The most frequent SV type is deletions, and the least frequent is insertions.*

```{r eval=TRUE}
# ANSWER 1.2

sv %>%
  rownames_to_column('patients') %>%
  melt(id.vars = 'patients', variable.name = 'SV_type', value.name = 'count') %>%
  group_by(SV_type) %>%
  summarise(total = sum(count)) %>%
  arrange(desc(total))

```

### Question 2: Is this normal?

Some analyses are contingent on distributional assumptions. For example, they may assume values are normally distributed. We can test the assumption that a sample is normally distributed with a QQ plot:

```{r}
set.seed(124)
x=rnorm(100)
qqnorm( x )
qqline( x )
```

**QUESTION 2.1** Generate a QQ plot to evaluate the assumption that deletions are normally distributed. Are deletions normally distributed?

*The deletions are not normally distributed. The QQ plot shows a deviation from the line, particularly at the tails.*

```{r eval=TRUE}
# ANSWER 2.1
deletions = sv$deletions
qqnorm( deletions )
qqline( deletions )
```

### Question 3: It's not normal

Data that are not normally distributed can be coerced towards a normal distribution by transforming the data. How could you transform the distribution of deletions so that it's closer to normal?

**QUESTION 3.1** Replot the QQ plot after performing a log transformation to see what effect your transformation had. Did this transformation make the sample more similar to a normal distribution?

**Note: leave the data as their original counts for the rest of the questions. Just transform for this question.**

*The log transformation makes the deletions more similar to a normal distribution.*

```{r eval=TRUE}
# ANSWER 3.1
qqnorm( log(deletions) )
qqline( log(deletions) )
```

### Question 4: We belong together

Structural variations arise from DNA damage that is not repaired. By analyzing tumor genomes, we can figure out the kind of DNA damage that occurred by studying the patterns of SVs.

The null model is that there is no relationship between the number of any type of SV. Alternatively, there might be an association between some of the SV types, suggesting something in common about their etiology.

**QUESTION 4.1** Calculate pairwise correlation between all five types of SV and plot the resulting correlation coefficients as a heat map. Try both Pearson correlation (the parametric default method in R) and non-parametric Spearman rank correlation, to see if it matters.

*Hint for plotting a simple correlation heatmap, where the matrix X contains the values to plot in the heatmap:*

```{r eval=TRUE}
# ANSWER 4.1
X = sv %>% cor %>% round(3)

XTidy = melt( X, value.name="val", varnames = c("x", "y") )

ggplot( XTidy, aes( x, y ) ) + 
  geom_tile( aes( fill = val ) ) + 
  geom_text( aes( label = val ) ) +
  scale_fill_gradient2( low = "blue", high = "red" ) + 
  theme_minimal()
```

**QUESTION 4.2** Which types of SV are most strongly correlated with each other? Without formal testing, do the correlation data support the null model, or is there reason to investigate an alternative model? Which pairs of SV are most likely to occur in similar counts?

*The most strongly correlated SV types are `duplications::inversions`*

```{r eval=TRUE}
# ANSWER 4.2
XTidy %>% filter( val < 1 ) %>% arrange( desc(val) )


```

**QUESTION 4.3 (BONUS)**: Why are the correlation values so different when comparing Spearman rank correlation to Pearson correlation? What might be driving these differences? Does it matter?

```{r eval=TRUE}
# ANSWER 4.3

cbind(
  # Spearman rank correlation
  sv %>% cor(method = "spearman") %>% round(3) %>% 
    melt(value.name="spearman", varnames = c("x", "y") ) %>% 
    mutate(index = paste(x, y, sep='::') ) %>% select(-x, -y) %>% column_to_rownames("index"),
  
  # Pearson correlation
  sv %>% cor(method = "pearson") %>% round(3) %>% 
    melt(value.name="pearson", varnames = c("x", "y") ) %>%
    mutate(index = paste(x, y, sep='::') ) %>% select(-x, -y) %>% column_to_rownames("index")

)
```

### Question 5: Outliers of interest

Let's drill down on two contrasting pairs of SVs:

1)  duplications and inversions
2)  deletions and inversions

**QUESTION 5.1** Create two scatter plots: duplications vs inversions, and deletions vs. inversions. Based on question 4, we'd expect the counts of these SVs to be somewhat correlated with each other. Does this hold up? Are there samples that are outliers from the linear trend in these comparisons?

Samples that deviate from a relationship like this might be of particular interest.

_The scatter plots show a linear relationship between the SV types (there is a positive slope in the linear regression line), but there are some samples that are outliers from the linear trend._

```{r eval=TRUE}
# ANSWER 5.1

sv %>% ggplot(aes(x = duplications, y = inversions)) +
  geom_point() +
  geom_abline() +
  geom_smooth(method = 'lm') +
  ggtitle('Duplications vs Inversions')

sv %>% ggplot(aes(x = deletions, y = inversions)) +
  geom_point() +
  geom_abline() +
  geom_smooth(method = 'lm') +
  ggtitle('Deletions vs Inversions')

```

### Question 6: Why the duplicates? Why the duplicates?

Let's drill down on the duplications. Look at your plot comparing the number of duplications to the number of inversions. Note that there are three samples that have far more duplications than any other sample, and four samples that have both a large number of inversions *and* a large (though not the highest) number of duplications. Looking at this plot, we might wonder if there is something special about the three samples that have a lot of duplications but not a lot of inversions.

The *mut* matrix that you loaded contains one row for each sample and one column for each of 15 genes, with a TRUE value if there is a biallelic inactivation of that gene in that sample.

**QUESTION 6.1** We'll test the hypothesis that tumors with a particular gene inactivation acquire a lot more duplications than tumors lacking that inactivation. Test this hypothesis by performing a Wilcoxon test comparing the number of duplicates in tumors with *vs.* without mutation in each gene. Create a barplot of -log10( *p* ) and nominate the strongest hit as worthy of further investigation.

```{r eval=TRUE}
# ANSWER 6.1

# a series of Wilcoxon tests, one for each gene ...

# here is the co-pilot code to get you started (!)
mut %>% 
  mutate( duplications = sv[row.names(mut), 'duplications'] ) %>%
  pivot_longer(-duplications, names_to = 'gene', values_to = 'mutated') %>%
  group_by(gene) %>%
  summarise( p = wilcox.test( duplications ~ mutated )$p.value ) %>%
  ggplot(aes(x = gene, y = -log10(p))) +
  geom_bar(stat = 'identity') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Question 7: Why so many ~~deletions~~?

Now let's take a close look at deletions. Look at the scatter plot you made comparing inversions *vs* deletions. There tends to be a linear relationship, even for samples with large numbers of inversions, but there is a set of samples that have lots of deletions but not a lot of inversions.

**QUESTION 7.1** You might hypothesize that tumors that have inactivated a DNA repair gene harbor a lot more deletions than normal tumors. Test this hypothesis by performing a Wilcox test comparing the number of deletions in tumors with *vs.* without mutation in each gene. This time, instead of a barplot, create a volcano plot to compare the difference in means (as the effect) vs. the -log10(*p*) as the statistical strength. Does this analysis nominate any gene as associated with large numbers of deletions?

_Since we test for more deletions, I use the alternative hypothesis 'greater'._

```{r eval=TRUE}
# ANSWER 7.1

mut %>% 
  mutate( deletions = sv[row.names(mut), 'deletions'] ) %>%
  pivot_longer(-deletions, names_to = 'gene', values_to = 'mutated') %>%
  group_by(gene) %>%
  summarise(
    # run the Wilcoxon test and return effect size
    effect_size = (mean( deletions[mutated] ) - mean( deletions[!mutated] )),
    # run the Wilcoxon test and return p value
    p = wilcox.test( deletions ~ mutated)$p.value # , alternative = 'greater' 
  ) -> gene_stats

effect_size = gene_stats$effect_size
logp = -log10( gene_stats$p )

# max(effect_size); min(effect_size); max(logp)

gene_names = dimnames(mut)[[2]]
plot( effect_size, logp, las=1, 
      xlim=c(-50,200), 
      ylim=c(0,6),
      xlab="change in deletions associated with mutation")
text( effect_size, logp + 0.12, gene_names ) # show gene names on the plot
abline( v=0, col='gray', lty=2 )
abline( h=-log10(0.05), col='gray', lty=2 )
```

**QUESTION 7.2 (BONUS)** Re-run the test you performed in problem 7.1, using a *t test* rather than a Wilcoxon test. Explain why these tests have different performance and produce different results. Discuss the difference between ranking candidates based on *P* value and based on a combination of *P* value and effect size.

_I found this statement for comparison "The t-test compares mean scores, while the Wilcoxon test uses signed ranks to evaluate differences". As result, the P-values for the negative effect sizes in the t-test is better than the Wilcoxon test. Although, we couls use the `alternative = 'greater'` in the t-test or the Wilcoxon test to compare the effect sizes in the same way._


```{r eval=TRUE}
# ANSWER 7.2
mut %>%
  mutate( deletions = sv[row.names(mut), 'deletions'] ) %>%
  pivot_longer(-deletions, names_to = 'gene', values_to = 'mutated') %>%
  group_by(gene) %>%
  summarise(
    effect_size = mean( deletions[mutated] ) - mean( deletions[!mutated] ),
    p = t.test( deletions ~ mutated)$p.value #, alternative = 'greater' 
  ) -> gene_stats2

effect_size = gene_stats2$effect_size
logp = -log10( gene_stats2$p )

# max(effect_size); min(effect_size); max(logp)

gene_names = dimnames(mut)[[2]]
plot( effect_size, logp, las=1, 
      xlim=c(-50,200), 
      ylim=c(0,6),
      xlab="change in deletions associated with mutation")
text( effect_size, logp + 0.12, gene_names ) # show gene names on the plot
abline( v=0, col='gray', lty=2 )
abline( h=-log10(0.05), col='gray', lty=2 )

```
